[
  {
    "objectID": "notes/introduccion.html",
    "href": "notes/introduccion.html",
    "title": "Introducci√≥n",
    "section": "",
    "text": "El objetivo de estos apuntes es estudiar en detalle el marco matem√°tico que subyace a los modelos de difusi√≥n, poniendo √©nfasis en la formulaci√≥n continua del proceso generativo y en las herramientas anal√≠ticas necesarias para comprenderlos de manera rigurosa.",
    "crumbs": [
      "Inicio",
      "Notas",
      "Introducci√≥n"
    ]
  },
  {
    "objectID": "notes/ejemplos_numericos.html",
    "href": "notes/ejemplos_numericos.html",
    "title": "Ejemplos Num√©ricos",
    "section": "",
    "text": "Hola\n\\[\n\\int_0^1 x^2 \\, dx = \\frac{1}{3}\n\\]\n\\[\ne^{i\\pi} + 1 = 0\n\\]\n\ndef function(x):\n  print(x)",
    "crumbs": [
      "Inicio",
      "Notas",
      "Ejemplos Num√©ricos"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site",
    "crumbs": [
      "Inicio",
      "General",
      "About"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inicio",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\nContenidos\nüëâ Comienza aqu√≠:\nIntroducci√≥n a los modelos de difusi√≥n",
    "crumbs": [
      "Inicio",
      "General",
      "Inicio"
    ]
  },
  {
    "objectID": "notes/historia.html",
    "href": "notes/historia.html",
    "title": "Historia",
    "section": "",
    "text": "Desde sus inicios, la inteligencia artificial (IA) estuvo orientada principalmente a tareas de predicci√≥n, como clasificaci√≥n y regresi√≥n. Sin embargo, a partir de la d√©cada de 2010, el foco comenz√≥ a desplazarse hacia el aprendizaje generativo, cuyo objetivo es modelar y muestrear distribuciones de probabilidad de alta complejidad y dimensionalidad. Este cambio permiti√≥ la generaci√≥n de objetos estructurados ‚Äîim√°genes, audio, video y texto‚Äî con un alto grado de regularidad estad√≠stica y similitud con los datos reales.\nDurante esta etapa inicial del aprendizaje generativo profundo, dos enfoques dominaron el lenguaje moderno de los modelos generativos. En 2013, los autoencoders variacionales (VAEs) introdujeron un modelo probabil√≠stico latente entrenado mediante m√°xima verosimilitud variacional, caracterizado por una formulaci√≥n estad√≠stica clara y un entrenamiento estable. No obstante, las aproximaciones variacionales tienden a inducir distribuciones latentes excesivamente simples, lo que suele traducirse en muestras suavizadas. En 2014, las redes generativas adversarias (GANs) reformularon el problema generativo como un juego minimax entre una red generadora y una discriminadora, logrando muestras de alta calidad visual, pero a costa de din√°micas de entrenamiento inestables, alta sensibilidad a la inicializaci√≥n y problemas recurrentes como el colapso de modos.\nPosteriormente, surgieron otros enfoques con mayor fidelidad estad√≠stica. Los modelos autorregresivos (2015) modelan expl√≠citamente la factorizaci√≥n de la distribuci√≥n conjunta, mientras que los normalizing flows (2016) construyen transformaciones invertibles con densidades expl√≠citas. Si bien ambos ofrecen fundamentos probabil√≠sticos s√≥lidos, presentan limitaciones pr√°cticas relevantes: los modelos autorregresivos requieren muestreos secuenciales costosos, y los flujos imponen restricciones estructurales que dificultan su escalamiento a distribuciones altamente complejas.\nEn este contexto aparecen los modelos de difusi√≥n, propuestos conceptualmente en 2015, que introducen la idea de un proceso estoc√°stico que degrada progresivamente los datos hacia ruido y aprende una din√°mica inversa para su reconstrucci√≥n. Sin embargo, esta idea no se consolid√≥ en la pr√°ctica sino hasta 2020, con la introducci√≥n de los Denoising Diffusion Probabilistic Models (DDPM), que resolvieron problemas de inestabilidad en el entrenamiento y permitieron generar muestras de alta calidad de manera consistente. Desde entonces, los modelos de difusi√≥n han prevalecido frente a enfoques anteriores y se han consolidado como el paradigma dominante para generaci√≥n de alta calidad. Sistemas ampliamente conocidos como Stable Diffusion, DALL¬∑E (2 y 3) y Midjourney se basan en este tipo de modelos.",
    "crumbs": [
      "Inicio",
      "Notas",
      "Historia"
    ]
  }
]